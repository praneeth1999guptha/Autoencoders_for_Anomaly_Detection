# Autoencoders_for_Anomaly_Detection
Implement autoencoder and explore its application for a real-world problem related to anomaly detection.
# Autoencoders for Anomaly Detection (AWS CloudWatch, NAB)

_Unsupervised multi-metric timeâ€‘series anomaly detection using dense and LSTM autoencoders in PyTorch._

This repository accompanies the notebook **`notebooks/Autoencoders for Anomaly Detection.ipynb`**, which trains autoencoders to detect anomalies in AWS CloudWatchâ€“style metrics derived from the **Numenta Anomaly Benchmark (NAB)** dataset.

> **Highlight:** Final LSTM Autoencoder reached a **pseudo accuracy â‰ˆ 96.8%** on the test set when flagging anomalies using the **85thâ€‘percentile reconstructionâ€‘error threshold**, with stable train/validation loss curves and clearly separated error distributions (see notebook figures).

---

## âœ¨ What this project does

- Aggregates several CloudWatchâ€‘like CSV time series into a single aligned dataframe (forwardâ€‘filled), then engineers features.
- Trains two unsupervised models:
  - **Small Dense Autoencoder** (tabular features)
  - **LSTM Autoencoder** (sequence modeling with a sliding window)
- Evaluates via **reconstruction error (MSE / RMSE)** and flags anomalies by thresholding error (percentile/IQR).
- Includes exploratory visuals: **ACF plots**, **recent-window heatmaps**, loss curves, and error histograms.

---

## ðŸ“¦ Data

- **Source:** *Numenta Anomaly Benchmark (NAB)* â€” Kaggle: https://www.kaggle.com/datasets/boltzmannbrain/nab  
- **What you need:** A directory of CSV files whose filenames contain these patterns (the notebook uses `glob` to find them):
  - `*cpu_utilization*.csv` â†’ **CPU**
  - `*disk_write_bytes*.csv` â†’ **Disk**
  - `*network_in*.csv` â†’ **Network**
  - `*elb_request_count*.csv` â†’ **ELB**
  - `*rds_cpu_utilization*.csv` â†’ **RDS**
  - `*grok_asg_anomaly*.csv` â†’ **ASG**
- The notebook merges them into a multi-metric table and saves:
  - `cloudwatch_multimetric_aggregated.csv` (aligned, forwardâ€‘filled, sorted by timestamp)

> Set the path at the top of the notebook: `DATA_FOLDER = "/path/to/your/data"`.

---

## ðŸ§ª Feature engineering & preprocessing

Implemented in `preprocess_features_v2`:
- Marks **sparse metrics** (`Disk`, `Network`, `ELB`) with
  - a **binary indicator** (`*_bin`) for nonâ€‘zero activity, and
  - a **logâ€‘magnitude** feature (`*_log = log1p(value)` clipped to high percentiles).
- Keeps **dense metrics** (`CPU`, `RDS`, `ASG`) continuous.
- Scales nonâ€‘binary columns with **RobustScaler** (resistant to outliers).

Optional data augmentation: **jitter** a subset of training samples with small Gaussian noise (Ïƒâ‰ˆ0.03).

---

## ðŸ§  Models

### 1) Small Dense Autoencoder
- **Encoder/Decoder:** Linear â†’ ReLU â†’ Dropout; bottleneck size â‰ˆ **48**
- **Loss:** MSE; **Optimizer:** Adam
- Example training settings: `epochs=30`, `batch_size=64`, `lrâ‰ˆ9.76eâ€‘4`, `weight_decayâ‰ˆ1.86eâ€‘6`, `dropoutâ‰ˆ0.22`

### 2) LSTM Autoencoder
- **Sequence window:** `seq_length=10`
- **Encoder/Decoder:** LSTM (hidden_dim=32, num_layers=1) â†’ bottleneck **16**
- **Loss:** MSE; **Optimizer:** Adam; **Scheduler:** ReduceLROnPlateau
- Example training settings: `epochs=20`, `batch_size=64`, `lrâ‰ˆ1.15eâ€‘4`, `weight_decayâ‰ˆ5.97eâ€‘5`, `dropoutâ‰ˆ0.10`

> Many hyperparameters in the notebook were selected via **Optuna** trials.

---

## ðŸ§® Evaluation & anomaly scoring

- Compute **perâ€‘sample reconstruction error** (MSE).  
- Choose a threshold:
  - **Percentile method:** e.g., **85th percentile** of train errors (default shown)
  - **IQR method:** `Q3 + 1.5Ã—IQR` from train errors
- Flag anomalies where `error > threshold`.
- Visuals: loss curves, **train vs test error histograms** with threshold line.
- Reported in the notebook:
  - **Pseudo accuracy â‰ˆ 96.79%** (e.g., `5269/5444` test windows â‰¤ 85thâ€‘percentile threshold).  
    _â€œPseudoâ€ means we donâ€™t use groundâ€‘truth labels here; we evaluate how well the chosen threshold separates typical from atypical behavior._

---

## ðŸš€ Getting started

### 1) Environment
```bash
python -m venv .venv
source .venv/bin/activate  # Windows: .venv\Scripts\activate
pip install --upgrade pip
pip install -r requirements.txt  # see below
```

### 2) Data
- Download NAB and place the relevant CSVs in a folder (see patterns above).
- Open the notebook and set `DATA_FOLDER` to that folder path.

### 3) Run
```bash
jupyter notebook notebooks/Autoencoders\ for\ Anomaly\ Detection.ipynb
```
Run cells in order:
1. **Step 1: Data preparation** (merge CSVs â†’ `cloudwatch_multimetric_aggregated.csv`)
2. **Step 2: Autoencoder model building** (choose dense or LSTM)
3. **Step 3: Evaluation and analysis** (thresholding & visuals)

> GPU is autoâ€‘detected; CPU also works (slower).

---



---

## ðŸ”– Citation & acknowledgments

- Lavin, A., & Ahmad, S. (2015). **Evaluating Realâ€‘Time Anomaly Detection Algorithms â€“ the Numenta Anomaly Benchmark (NAB).**
- **Dataset:** *Numenta Anomaly Benchmark (NAB)* â€” Kaggle: https://www.kaggle.com/datasets/boltzmannbrain/nab
- Thanks to the PyTorch, pandas, scikitâ€‘learn, statsmodels, and seaborn communities.

---
